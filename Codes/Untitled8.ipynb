{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_s9cesHs94Q",
        "outputId": "8a6d96b0-aaa8-43df-b7af-ffff11c35089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = 'compressed.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as f:\n",
        "  f.extractall()\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import sklearn.metrics as metrics\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import cv2\n",
        "import imghdr\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "YNBFAMmDuXdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm train/.DS_Store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd06BH4o4QwU",
        "outputId": "16035b92-d745-4c27-bf41-fb0b9aed01d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'train/.DS_Store': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rm test/.DS_Store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aarwFB44Y6J",
        "outputId": "3959604a-41f7-4d9e-b077-1b106acfeba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'test/.DS_Store': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folders = ['train', 'test']\n",
        "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
        "\n",
        "for folder in folders:\n",
        "  for image_class in os.listdir(folder): \n",
        "      print(image_class)\n",
        "      for image in os.listdir(os.path.join(folder, image_class)):\n",
        "          image_path = os.path.join(folder, image_class, image)\n",
        "          try: \n",
        "              img = cv2.imread(image_path)\n",
        "              tip = imghdr.what(image_path)\n",
        "              if tip not in image_exts: \n",
        "                  print('Image not in ext list {}'.format(image_path))\n",
        "                  os.remove(image_path)\n",
        "          except Exception as e: \n",
        "              print('Issue with image {}'.format(image_path))\n",
        "              # os.remove(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqaZJ1IFubui",
        "outputId": "fcd1c64a-09fb-401a-c35d-1a2668e6d6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "white_knight\n",
            "black_knight\n",
            "empty\n",
            "white_pawn\n",
            "black_queen\n",
            "white_queen\n",
            "white_king\n",
            "black_pawn\n",
            "white_rook\n",
            "black_bishop\n",
            "white_bishop\n",
            "black_king\n",
            "black_rook\n",
            "white_knight\n",
            "black_knight\n",
            "empty\n",
            "white_pawn\n",
            "black_queen\n",
            "white_queen\n",
            "white_king\n",
            "black_pawn\n",
            "white_rook\n",
            "black_bishop\n",
            "white_bishop\n",
            "black_king\n",
            "black_rook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trdata = ImageDataGenerator(validation_split=0.3)\n",
        "train_data_gen = trdata.flow_from_directory(directory=\"train\", target_size=(256,256), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
        "validation_data_gen = trdata.flow_from_directory(directory=\"train\", target_size=(256,256), shuffle=True, class_mode=\"categorical\", subset=\"validation\")\n",
        "tsdata = ImageDataGenerator()\n",
        "test_data_gen = tsdata.flow_from_directory(directory=\"test\", target_size=(256,256),shuffle=True, class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W-2rtJM4e8f",
        "outputId": "ce0c7d39-fd11-401d-f135-73ccb5113b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1665 images belonging to 13 classes.\n",
            "Found 703 images belonging to 13 classes.\n",
            "Found 832 images belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(input_shape = (256,256,3), weights = \"imagenet\", include_top = False)\n",
        "for layer in vgg.layers:\n",
        " layer.trainable = False\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(128, activation = \"relu\", kernel_initializer=\"he_normal\")(x) \n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
        "x = Dense(64, activation = \"relu\", kernel_initializer=\"he_normal\")(x) \n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
        "x = Dense(13, activation = \"softmax\")(x) \n",
        "model = Model(inputs = vgg.input, outputs = x)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "iOuDgbB_5S78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_steps_per_epoch = np.ceil(train_data_gen.samples / 20)\n",
        "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 20)\n",
        "\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True,verbose=1)\n",
        "\n",
        "model.fit_generator(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch,epochs=10, verbose=1, callbacks=[early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s4nkMQt51Au",
        "outputId": "faeb26f5-1fed-4192-c92b-212f304c483f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-8ad1c482765c>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch,epochs=10, verbose=1, callbacks=[early_stopping_cb])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/84 [=================>............] - ETA: 11:06 - loss: 1.9859 - accuracy: 0.4180"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 840.0 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 36.0 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r84/84 [==============================] - 1646s 20s/step - loss: 1.9859 - accuracy: 0.4180 - val_loss: 3.1328 - val_accuracy: 0.2632\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98ea1366b0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}