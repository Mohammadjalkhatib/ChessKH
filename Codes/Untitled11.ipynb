{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "j2IonlY6XBve",
    "outputId": "ba713237-60df-4cc9-ec57-93c57797e081"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'khateeb_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZipFile\n\u001b[0;32m      3\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkhateeb_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m   f\u001b[38;5;241m.\u001b[39mextractall()\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1249\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1249\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'khateeb_data'"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "file_name = 'khateeb_data'\n",
    "\n",
    "with ZipFile(file_name, 'r') as f:\n",
    "  f.extractall()\n",
    "  print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moath\\Downloads\\khateeb_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.join(current_directory, \"khateeb_data\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "     ------------------------------------ 272.8/272.8 MB 646.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     -------------------------------------- 65.5/65.5 kB 708.3 kB/s eta 0:00:00\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.10.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 2.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.2-cp310-abi3-win_amd64.whl (422 kB)\n",
      "     -------------------------------------- 422.5/422.5 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.1.0-cp310-cp310-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.4/120.4 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.19.0-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------ 181.3/181.3 kB 994.3 kB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ------------------------------------ 151.7/151.7 kB 822.4 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.10-py3-none-any.whl size=1480617 sha256=912326ad55e5250dda956c0e0a293ebd1ef1bcafbac9b0e12878e4dbc5209838\n",
      "  Stored in directory: c:\\users\\moath\\appdata\\local\\pip\\cache\\wheels\\f8\\55\\5b\\9dde9a2af48db48d64b8cc3877f0670cf11c5d78de392c3f05\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.19.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 jax-0.4.10 keras-2.12.0 libclang-16.0.0 ml-dtypes-0.1.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\moath\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N4ymSM6zeJFn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import cv2\n",
    "import imghdr\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvMXnI9TeJtC"
   },
   "outputs": [],
   "source": [
    "rm train/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSJjDzryeNcX"
   },
   "outputs": [],
   "source": [
    "rm test/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aZ4f-eOjeOA0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_bishop\n",
      "black_king\n",
      "black_knight\n",
      "black_pawn\n",
      "black_queen\n",
      "black_rook\n",
      "empty\n",
      "white_bishop\n",
      "white_king\n",
      "white_knight\n",
      "white_pawn\n",
      "white_queen\n",
      "white_rook\n"
     ]
    }
   ],
   "source": [
    "folders = ['train', 'test']\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n",
    "for image_class in os.listdir(path): \n",
    "  print(image_class)\n",
    "  for image in os.listdir(os.path.join(path, image_class)):\n",
    "      image_path = os.path.join(path, image_class, image)\n",
    "      try: \n",
    "          img = cv2.imread(image_path)\n",
    "          tip = imghdr.what(image_path)\n",
    "          if tip not in image_exts: \n",
    "              print('Image not in ext list {}'.format(image_path))\n",
    "              os.remove(image_path)\n",
    "      except Exception as e: \n",
    "          print('Issue with image {}'.format(image_path))\n",
    "          # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WDH63mhvePx-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1798 images belonging to 13 classes.\n",
      "Found 437 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(rotation_range = 60, validation_split=0.2)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(299,299), shuffle=True, class_mode=\"categorical\", subset=\"training\", batch_size = 20)\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(299,299), shuffle=True, class_mode=\"categorical\", subset=\"validation\", batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pLlyF_9NegW0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TEXUpLI0elHm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 702s 12s/step - loss: 1.3737 - accuracy: 0.5695 - val_loss: 6.2816 - val_accuracy: 0.2929\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 640s 11s/step - loss: 0.5393 - accuracy: 0.8337 - val_loss: 2.8879 - val_accuracy: 0.5286\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 641s 11s/step - loss: 0.3627 - accuracy: 0.8882 - val_loss: 2.0862 - val_accuracy: 0.6110\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 639s 11s/step - loss: 0.3474 - accuracy: 0.8971 - val_loss: 2.6472 - val_accuracy: 0.5515\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 638s 11s/step - loss: 0.2358 - accuracy: 0.9288 - val_loss: 2.0215 - val_accuracy: 0.6384\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 643s 11s/step - loss: 0.2834 - accuracy: 0.9227 - val_loss: 1.8223 - val_accuracy: 0.6316\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 640s 11s/step - loss: 0.2373 - accuracy: 0.9377 - val_loss: 1.6484 - val_accuracy: 0.6957\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 638s 11s/step - loss: 0.1787 - accuracy: 0.9455 - val_loss: 1.4598 - val_accuracy: 0.7185\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 638s 11s/step - loss: 0.1452 - accuracy: 0.9549 - val_loss: 1.6779 - val_accuracy: 0.6819\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 609s 11s/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 1.7247 - val_accuracy: 0.7071\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 606s 11s/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 2.3672 - val_accuracy: 0.6201\n",
      "Epoch 12/15\n",
      "50/57 [=========================>....] - ETA: 1:00 - loss: 0.1605 - accuracy: 0.9638"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m validation_steps_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(validation_data_gen\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      4\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "vgg2 = VGG19(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "y = tf.keras.layers.Flatten()(vgg2.output)\n",
    "y = tf.keras.layers.Dense(128, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dropout(0.2)(y)\n",
    "y = tf.keras.layers.Dense(128, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dropout(0.2)(y)\n",
    "y = tf.keras.layers.Dense(128, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dropout(0.2)(y)\n",
    "y = tf.keras.layers.Dense(64, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.Dense(13, activation = \"softmax\")(y)\n",
    "\n",
    "model2 = Model(inputs = vgg2.input, outputs = y)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "57/57 [==============================] - 1783s 31s/step - loss: 2.3825 - accuracy: 0.2108 - val_loss: 41.1772 - val_accuracy: 0.1510\n",
      "Epoch 2/12\n",
      "57/57 [==============================] - 1786s 31s/step - loss: 1.8407 - accuracy: 0.3204 - val_loss: 21.0104 - val_accuracy: 0.0801\n",
      "Epoch 3/12\n",
      "57/57 [==============================] - 1734s 30s/step - loss: 1.7000 - accuracy: 0.3587 - val_loss: 5.1337 - val_accuracy: 0.1556\n",
      "Epoch 4/12\n",
      "57/57 [==============================] - 1749s 31s/step - loss: 1.6176 - accuracy: 0.3771 - val_loss: 2.1906 - val_accuracy: 0.2449\n",
      "Epoch 5/12\n",
      "57/57 [==============================] - 1751s 31s/step - loss: 1.5541 - accuracy: 0.3960 - val_loss: 4.8963 - val_accuracy: 0.1739\n",
      "Epoch 6/12\n",
      "57/57 [==============================] - 1734s 31s/step - loss: 1.5627 - accuracy: 0.4027 - val_loss: 2.0432 - val_accuracy: 0.1968\n",
      "Epoch 7/12\n",
      " 1/57 [..............................] - ETA: 29:58 - loss: 1.4597 - accuracy: 0.3750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model2.fit(train_data_gen, validation_data=validation_data_gen, epochs=12, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1798 images belonging to 13 classes.\n",
      "Found 437 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(rotation_range = 60, validation_split=0.2)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(299,299), shuffle=True, class_mode=\"categorical\", subset=\"training\", batch_size = 20)\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(299,299), shuffle=True, class_mode=\"categorical\", subset=\"validation\", batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "incep = InceptionV3(input_shape = (299,299,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in incep.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "y = tf.keras.layers.Flatten()(incep.output)\n",
    "y = tf.keras.layers.Dense(32, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dropout(0.2)(y)\n",
    "y = tf.keras.layers.Dense(32, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dropout(0.2)(y)\n",
    "y = tf.keras.layers.Dense(32, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dropout(0.2)(y)\n",
    "y = tf.keras.layers.Dense(32, activation=tf.nn.swish, kernel_initializer=\"he_normal\")(y)\n",
    "y = tf.keras.layers.Dense(13, activation = \"softmax\")(y)\n",
    "\n",
    "incep_model = Model(inputs = incep.input, outputs = y)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "incep_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "90/90 [==============================] - 536s 6s/step - loss: 2.3823 - accuracy: 0.1802 - val_loss: 2.8023 - val_accuracy: 0.1190\n",
      "Epoch 2/12\n",
      "90/90 [==============================] - 504s 6s/step - loss: 2.0285 - accuracy: 0.2280 - val_loss: 1.8740 - val_accuracy: 0.2517\n",
      "Epoch 3/12\n",
      "90/90 [==============================] - 503s 6s/step - loss: 1.8925 - accuracy: 0.2775 - val_loss: 1.9320 - val_accuracy: 0.1739\n",
      "Epoch 4/12\n",
      "90/90 [==============================] - 503s 6s/step - loss: 1.8383 - accuracy: 0.2987 - val_loss: 1.9894 - val_accuracy: 0.2288\n",
      "Epoch 5/12\n",
      "90/90 [==============================] - 502s 6s/step - loss: 1.7827 - accuracy: 0.3343 - val_loss: 1.8765 - val_accuracy: 0.2609\n",
      "Epoch 6/12\n",
      "90/90 [==============================] - 501s 6s/step - loss: 1.6833 - accuracy: 0.3459 - val_loss: 2.0687 - val_accuracy: 0.1808\n",
      "Epoch 7/12\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.6264 - accuracy: 0.3687Restoring model weights from the end of the best epoch: 2.\n",
      "90/90 [==============================] - 503s 6s/step - loss: 1.6264 - accuracy: 0.3687 - val_loss: 2.0018 - val_accuracy: 0.2380\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cfcde89000>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "incep_model.fit(train_data_gen, validation_data=validation_data_gen, epochs=12, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1798 images belonging to 13 classes.\n",
      "Found 437 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(rotation_range = 60, validation_split=0.2)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"training\", batch_size = 10)\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"validation\", batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(720, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 198s 3s/step - loss: 3.4588 - accuracy: 0.2940 - val_loss: 23.1128 - val_accuracy: 0.0714\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 197s 3s/step - loss: 3.2994 - accuracy: 0.4261 - val_loss: 9.7720 - val_accuracy: 0.3071\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 196s 3s/step - loss: 2.8773 - accuracy: 0.4754 - val_loss: 5.4335 - val_accuracy: 0.3643\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 194s 3s/step - loss: 2.8386 - accuracy: 0.5423 - val_loss: 4.2415 - val_accuracy: 0.4357\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 196s 3s/step - loss: 2.3360 - accuracy: 0.5737 - val_loss: 2.0125 - val_accuracy: 0.4929\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 194s 3s/step - loss: 2.0262 - accuracy: 0.5739 - val_loss: 3.2312 - val_accuracy: 0.4214\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 194s 3s/step - loss: 1.6701 - accuracy: 0.6461 - val_loss: 1.8819 - val_accuracy: 0.5214\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 194s 3s/step - loss: 1.3228 - accuracy: 0.6813 - val_loss: 1.8935 - val_accuracy: 0.6071\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 195s 3s/step - loss: 0.8622 - accuracy: 0.7799 - val_loss: 2.8244 - val_accuracy: 0.4214\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 195s 3s/step - loss: 0.8853 - accuracy: 0.7782 - val_loss: 1.4624 - val_accuracy: 0.5929\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 194s 3s/step - loss: 0.7822 - accuracy: 0.7754 - val_loss: 1.5561 - val_accuracy: 0.5357\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 194s 3s/step - loss: 0.6515 - accuracy: 0.8169 - val_loss: 1.1086 - val_accuracy: 0.6357\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 196s 3s/step - loss: 0.6922 - accuracy: 0.8070 - val_loss: 1.7195 - val_accuracy: 0.5786\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 194s 3s/step - loss: 0.5610 - accuracy: 0.8281 - val_loss: 1.2061 - val_accuracy: 0.6786\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 195s 3s/step - loss: 0.4695 - accuracy: 0.8544 - val_loss: 1.9754 - val_accuracy: 0.5929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf8009b2b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1798 images belonging to 13 classes.\n",
      "Found 437 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(rotation_range = 60, validation_split=0.2)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 589s 10s/step - loss: 1.2346 - accuracy: 0.6702 - val_loss: 2.2747 - val_accuracy: 0.4073\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 582s 10s/step - loss: 0.3690 - accuracy: 0.9277 - val_loss: 1.3253 - val_accuracy: 0.5812\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 583s 10s/step - loss: 0.1736 - accuracy: 0.9655 - val_loss: 1.1863 - val_accuracy: 0.6018\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 582s 10s/step - loss: 0.0965 - accuracy: 0.9878 - val_loss: 1.0383 - val_accuracy: 0.6384\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 585s 10s/step - loss: 0.0750 - accuracy: 0.9855 - val_loss: 1.0207 - val_accuracy: 0.6842\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 583s 10s/step - loss: 0.0499 - accuracy: 0.9900 - val_loss: 1.0689 - val_accuracy: 0.6407\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 582s 10s/step - loss: 0.0314 - accuracy: 0.9972 - val_loss: 0.9844 - val_accuracy: 0.6796\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 582s 10s/step - loss: 0.0217 - accuracy: 0.9989 - val_loss: 1.0272 - val_accuracy: 0.6682\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 582s 10s/step - loss: 0.0205 - accuracy: 0.9989 - val_loss: 1.1018 - val_accuracy: 0.6636\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 581s 10s/step - loss: 0.0328 - accuracy: 0.9939 - val_loss: 1.2947 - val_accuracy: 0.6384\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 580s 10s/step - loss: 0.0188 - accuracy: 0.9989 - val_loss: 1.0033 - val_accuracy: 0.6613\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 578s 10s/step - loss: 0.0139 - accuracy: 0.9994 - val_loss: 0.9263 - val_accuracy: 0.7071\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 577s 10s/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 1.0003 - val_accuracy: 0.6819\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 580s 10s/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.8958 - val_accuracy: 0.6979\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 583s 10s/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.9900 - val_accuracy: 0.6796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf88406380>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 616s 11s/step - loss: 0.9948 - accuracy: 0.7086 - val_loss: 1.7415 - val_accuracy: 0.5400\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 622s 11s/step - loss: 0.3216 - accuracy: 0.9321 - val_loss: 1.1987 - val_accuracy: 0.6293\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 667s 12s/step - loss: 0.1724 - accuracy: 0.9722 - val_loss: 1.0209 - val_accuracy: 0.6705\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 671s 12s/step - loss: 0.1131 - accuracy: 0.9816 - val_loss: 0.9940 - val_accuracy: 0.6957\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 645s 11s/step - loss: 0.0867 - accuracy: 0.9822 - val_loss: 1.0465 - val_accuracy: 0.6590\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 655s 12s/step - loss: 0.0662 - accuracy: 0.9889 - val_loss: 0.9594 - val_accuracy: 0.6819\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.0642 - accuracy: 0.9872 - val_loss: 0.9679 - val_accuracy: 0.7094\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 623s 11s/step - loss: 0.0444 - accuracy: 0.9933 - val_loss: 1.1211 - val_accuracy: 0.6796\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 594s 11s/step - loss: 0.0359 - accuracy: 0.9944 - val_loss: 0.9304 - val_accuracy: 0.7071\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 588s 10s/step - loss: 0.0338 - accuracy: 0.9933 - val_loss: 0.9531 - val_accuracy: 0.7002\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 589s 10s/step - loss: 0.0266 - accuracy: 0.9972 - val_loss: 0.9739 - val_accuracy: 0.6865\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 595s 10s/step - loss: 0.0248 - accuracy: 0.9961 - val_loss: 0.9523 - val_accuracy: 0.7048\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 611s 11s/step - loss: 0.0252 - accuracy: 0.9956 - val_loss: 1.0569 - val_accuracy: 0.6751\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9950Restoring model weights from the end of the best epoch: 9.\n",
      "57/57 [==============================] - 601s 11s/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.9700 - val_accuracy: 0.6957\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf881b2530>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, validation_data=validation_data_gen, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 595s 10s/step - loss: 2.3496 - accuracy: 0.2108 - val_loss: 2.6816 - val_accuracy: 0.1556\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 579s 10s/step - loss: 1.8914 - accuracy: 0.3504 - val_loss: 1.7730 - val_accuracy: 0.3776\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 577s 10s/step - loss: 1.5851 - accuracy: 0.4333 - val_loss: 1.5232 - val_accuracy: 0.4439\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 578s 10s/step - loss: 1.4151 - accuracy: 0.4705 - val_loss: 1.4625 - val_accuracy: 0.4645\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 580s 10s/step - loss: 1.2438 - accuracy: 0.5317 - val_loss: 1.2718 - val_accuracy: 0.5195\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 577s 10s/step - loss: 1.1960 - accuracy: 0.5462 - val_loss: 1.1678 - val_accuracy: 0.5881\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 577s 10s/step - loss: 1.1320 - accuracy: 0.5595 - val_loss: 1.1756 - val_accuracy: 0.5378\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 578s 10s/step - loss: 1.0813 - accuracy: 0.5806 - val_loss: 1.1457 - val_accuracy: 0.5744\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 577s 10s/step - loss: 1.0170 - accuracy: 0.5929 - val_loss: 1.0145 - val_accuracy: 0.6453\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 577s 10s/step - loss: 0.9867 - accuracy: 0.6018 - val_loss: 1.0323 - val_accuracy: 0.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf906f3ca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, validation_data=validation_data_gen, epochs=10, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 588s 10s/step - loss: 2.5408 - accuracy: 0.1913 - val_loss: 2.8533 - val_accuracy: 0.2494\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 574s 10s/step - loss: 2.0378 - accuracy: 0.3065 - val_loss: 2.0281 - val_accuracy: 0.3524\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 574s 10s/step - loss: 1.7350 - accuracy: 0.3932 - val_loss: 1.7665 - val_accuracy: 0.4005\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 575s 10s/step - loss: 1.5095 - accuracy: 0.4700 - val_loss: 1.4811 - val_accuracy: 0.4416\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 573s 10s/step - loss: 1.3235 - accuracy: 0.5228 - val_loss: 1.3536 - val_accuracy: 0.4966\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 575s 10s/step - loss: 1.2108 - accuracy: 0.5645 - val_loss: 1.2290 - val_accuracy: 0.5629\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 572s 10s/step - loss: 1.1065 - accuracy: 0.6057 - val_loss: 1.1114 - val_accuracy: 0.5835\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 572s 10s/step - loss: 1.0388 - accuracy: 0.6201 - val_loss: 1.0837 - val_accuracy: 0.6178\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 572s 10s/step - loss: 0.9842 - accuracy: 0.6318 - val_loss: 1.0418 - val_accuracy: 0.5881\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 574s 10s/step - loss: 0.8820 - accuracy: 0.6835 - val_loss: 0.9709 - val_accuracy: 0.6476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf93c00a60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, validation_data=validation_data_gen, epochs=10, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 579s 10s/step - loss: 2.9833 - accuracy: 0.1752 - val_loss: 2.8231 - val_accuracy: 0.2998\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 575s 10s/step - loss: 2.0946 - accuracy: 0.2992 - val_loss: 1.9260 - val_accuracy: 0.3684\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 573s 10s/step - loss: 1.6875 - accuracy: 0.4644 - val_loss: 1.7206 - val_accuracy: 0.4508\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 573s 10s/step - loss: 1.4399 - accuracy: 0.5189 - val_loss: 1.6061 - val_accuracy: 0.4828\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 573s 10s/step - loss: 1.2113 - accuracy: 0.5996 - val_loss: 1.3917 - val_accuracy: 0.5606\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 573s 10s/step - loss: 1.0378 - accuracy: 0.6635 - val_loss: 1.2431 - val_accuracy: 0.6041\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 570s 10s/step - loss: 0.8694 - accuracy: 0.7097 - val_loss: 1.0956 - val_accuracy: 0.6430\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 571s 10s/step - loss: 0.7064 - accuracy: 0.7781 - val_loss: 1.1450 - val_accuracy: 0.6568\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 574s 10s/step - loss: 0.6504 - accuracy: 0.7875 - val_loss: 1.1265 - val_accuracy: 0.6339\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 574s 10s/step - loss: 0.5786 - accuracy: 0.8031 - val_loss: 1.0851 - val_accuracy: 0.6476\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 571s 10s/step - loss: 0.5139 - accuracy: 0.8326 - val_loss: 1.0240 - val_accuracy: 0.6751\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 571s 10s/step - loss: 0.4509 - accuracy: 0.8554 - val_loss: 1.0046 - val_accuracy: 0.6888\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 570s 10s/step - loss: 0.4235 - accuracy: 0.8654 - val_loss: 0.9911 - val_accuracy: 0.6773\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 573s 10s/step - loss: 0.3871 - accuracy: 0.8732 - val_loss: 0.9105 - val_accuracy: 0.7094\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 569s 10s/step - loss: 0.3851 - accuracy: 0.8782 - val_loss: 0.9707 - val_accuracy: 0.7208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cfa46765f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1798 images belonging to 13 classes.\n",
      "Found 437 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(validation_split=0.2)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 561s 10s/step - loss: 2.4866 - accuracy: 0.2408 - val_loss: 2.7462 - val_accuracy: 0.3227\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 550s 10s/step - loss: 1.5551 - accuracy: 0.4950 - val_loss: 1.6578 - val_accuracy: 0.4645\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 550s 10s/step - loss: 1.0954 - accuracy: 0.6468 - val_loss: 1.4490 - val_accuracy: 0.5286\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 550s 10s/step - loss: 0.8990 - accuracy: 0.7303 - val_loss: 1.3116 - val_accuracy: 0.5744\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 556s 10s/step - loss: 0.6971 - accuracy: 0.7875 - val_loss: 1.2583 - val_accuracy: 0.5904\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 554s 10s/step - loss: 0.5235 - accuracy: 0.8515 - val_loss: 1.2437 - val_accuracy: 0.6087\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 554s 10s/step - loss: 0.4477 - accuracy: 0.8704 - val_loss: 1.2875 - val_accuracy: 0.5927\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 555s 10s/step - loss: 0.3459 - accuracy: 0.9055 - val_loss: 1.3238 - val_accuracy: 0.5950\n",
      "Epoch 9/15\n",
      "54/57 [===========================>..] - ETA: 23s - loss: 0.2989 - accuracy: 0.9219"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m validation_steps_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(validation_data_gen\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      4\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1680 images belonging to 13 classes.\n",
      "Found 555 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(rotation_range = 30, validation_split=0.25)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(224,224), shuffle=True, class_mode=\"categorical\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 579s 11s/step - loss: 2.8069 - accuracy: 0.2030 - val_loss: 3.3231 - val_accuracy: 0.2703\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 579s 11s/step - loss: 1.8083 - accuracy: 0.4161 - val_loss: 2.1332 - val_accuracy: 0.3405\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 575s 11s/step - loss: 1.3750 - accuracy: 0.5631 - val_loss: 1.8259 - val_accuracy: 0.3892\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 574s 11s/step - loss: 1.0913 - accuracy: 0.6565 - val_loss: 1.6786 - val_accuracy: 0.4432\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 576s 11s/step - loss: 0.8337 - accuracy: 0.7548 - val_loss: 1.5887 - val_accuracy: 0.5207\n",
      "Epoch 6/15\n",
      " 4/53 [=>............................] - ETA: 6:41 - loss: 0.6581 - accuracy: 0.7812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m validation_steps_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(validation_data_gen\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      4\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1680 images belonging to 13 classes.\n",
      "Found 555 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(rotation_range = 30, validation_split=0.25)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(299,299), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(299,299), shuffle=True, class_mode=\"categorical\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "incep = InceptionV3(input_shape = (299,299,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in incep.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(incep.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "incep_model = Model(inputs = incep.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "incep_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 516s 10s/step - loss: 2.6138 - accuracy: 0.1655 - val_loss: 3.5190 - val_accuracy: 0.1802\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 507s 10s/step - loss: 2.0143 - accuracy: 0.2964 - val_loss: 2.2216 - val_accuracy: 0.2054\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 506s 10s/step - loss: 1.7748 - accuracy: 0.3607 - val_loss: 2.1622 - val_accuracy: 0.1730\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 503s 10s/step - loss: 1.6433 - accuracy: 0.3976 - val_loss: 1.9780 - val_accuracy: 0.2144\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 508s 10s/step - loss: 1.4987 - accuracy: 0.4500 - val_loss: 2.1101 - val_accuracy: 0.1802\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 505s 10s/step - loss: 1.4371 - accuracy: 0.4833 - val_loss: 2.1652 - val_accuracy: 0.1892\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 505s 10s/step - loss: 1.3252 - accuracy: 0.5083 - val_loss: 2.1866 - val_accuracy: 0.2036\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 504s 10s/step - loss: 1.2832 - accuracy: 0.5494 - val_loss: 2.2462 - val_accuracy: 0.1982\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1269 - accuracy: 0.5899Restoring model weights from the end of the best epoch: 4.\n",
      "53/53 [==============================] - 505s 10s/step - loss: 1.1269 - accuracy: 0.5899 - val_loss: 2.4668 - val_accuracy: 0.1964\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf87789ba0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "incep_model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1680 images belonging to 13 classes.\n",
      "Found 555 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(zoom_range = 0.2, validation_split=0.25)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(244,244), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(244,244), shuffle=True, class_mode=\"categorical\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 643s 12s/step - loss: 2.5894 - accuracy: 0.2298 - val_loss: 2.5765 - val_accuracy: 0.2685\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 638s 12s/step - loss: 1.6580 - accuracy: 0.4768 - val_loss: 1.7993 - val_accuracy: 0.4216\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 640s 12s/step - loss: 1.2158 - accuracy: 0.6173 - val_loss: 1.4886 - val_accuracy: 0.4937\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 637s 12s/step - loss: 0.9582 - accuracy: 0.7137 - val_loss: 1.4485 - val_accuracy: 0.4973\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 637s 12s/step - loss: 0.7296 - accuracy: 0.7798 - val_loss: 1.4142 - val_accuracy: 0.5279\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 639s 12s/step - loss: 0.5923 - accuracy: 0.8345 - val_loss: 1.3189 - val_accuracy: 0.5658\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 637s 12s/step - loss: 0.4947 - accuracy: 0.8500 - val_loss: 1.3703 - val_accuracy: 0.5766\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 636s 12s/step - loss: 0.3932 - accuracy: 0.8815 - val_loss: 1.3944 - val_accuracy: 0.5856\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 634s 12s/step - loss: 0.3621 - accuracy: 0.8935 - val_loss: 1.3885 - val_accuracy: 0.5802\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 635s 12s/step - loss: 0.3182 - accuracy: 0.9042 - val_loss: 1.3853 - val_accuracy: 0.5910\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.9196Restoring model weights from the end of the best epoch: 6.\n",
      "53/53 [==============================] - 636s 12s/step - loss: 0.2698 - accuracy: 0.9196 - val_loss: 1.5031 - val_accuracy: 0.6054\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf92bcfc10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 642s 12s/step - loss: 3.4332 - accuracy: 0.1048 - val_loss: 3.6345 - val_accuracy: 0.1784\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 634s 12s/step - loss: 2.6597 - accuracy: 0.1863 - val_loss: 2.3103 - val_accuracy: 0.2775\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 633s 12s/step - loss: 2.3478 - accuracy: 0.2429 - val_loss: 2.1086 - val_accuracy: 0.3135\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 634s 12s/step - loss: 2.1321 - accuracy: 0.3071 - val_loss: 1.9780 - val_accuracy: 0.3514\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 631s 12s/step - loss: 1.9579 - accuracy: 0.3411 - val_loss: 1.8955 - val_accuracy: 0.3622\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 633s 12s/step - loss: 1.8372 - accuracy: 0.3786 - val_loss: 1.8189 - val_accuracy: 0.3784\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 630s 12s/step - loss: 1.6840 - accuracy: 0.4268 - val_loss: 1.7632 - val_accuracy: 0.4306\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 631s 12s/step - loss: 1.6152 - accuracy: 0.4601 - val_loss: 1.6868 - val_accuracy: 0.4342\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 628s 12s/step - loss: 1.5444 - accuracy: 0.4673 - val_loss: 1.6145 - val_accuracy: 0.4505\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 627s 12s/step - loss: 1.4170 - accuracy: 0.5238 - val_loss: 1.5360 - val_accuracy: 0.4937\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 628s 12s/step - loss: 1.3223 - accuracy: 0.5429 - val_loss: 1.5250 - val_accuracy: 0.4829\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 628s 12s/step - loss: 1.2286 - accuracy: 0.5756 - val_loss: 1.4853 - val_accuracy: 0.4775\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 628s 12s/step - loss: 1.1958 - accuracy: 0.5720 - val_loss: 1.4209 - val_accuracy: 0.5099\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 629s 12s/step - loss: 1.1457 - accuracy: 0.6089 - val_loss: 1.3894 - val_accuracy: 0.5153\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 629s 12s/step - loss: 1.0630 - accuracy: 0.6280 - val_loss: 1.3540 - val_accuracy: 0.5297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d01ab310c0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 649s 12s/step - loss: 3.7259 - accuracy: 0.0827 - val_loss: 2.7338 - val_accuracy: 0.0991\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 633s 12s/step - loss: 3.2675 - accuracy: 0.0798 - val_loss: 2.5755 - val_accuracy: 0.1063\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 631s 12s/step - loss: 3.0851 - accuracy: 0.0810 - val_loss: 2.5906 - val_accuracy: 0.0703\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 628s 12s/step - loss: 3.0271 - accuracy: 0.0738 - val_loss: 2.5940 - val_accuracy: 0.0505\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 627s 12s/step - loss: 2.8725 - accuracy: 0.0851 - val_loss: 2.5790 - val_accuracy: 0.0667\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 625s 12s/step - loss: 2.8289 - accuracy: 0.0714 - val_loss: 2.5742 - val_accuracy: 0.1171\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 625s 12s/step - loss: 2.7553 - accuracy: 0.0798 - val_loss: 2.5693 - val_accuracy: 0.0631\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 629s 12s/step - loss: 2.7413 - accuracy: 0.0881 - val_loss: 2.5716 - val_accuracy: 0.0613\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 626s 12s/step - loss: 2.7036 - accuracy: 0.0792 - val_loss: 2.5747 - val_accuracy: 0.0649\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 627s 12s/step - loss: 2.6845 - accuracy: 0.0911 - val_loss: 2.5624 - val_accuracy: 0.0595\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 628s 12s/step - loss: 2.6604 - accuracy: 0.0857 - val_loss: 2.5639 - val_accuracy: 0.0703\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.6661 - accuracy: 0.0869"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m validation_steps_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(validation_data_gen\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      4\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1716\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1717\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1727\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1728\u001b[0m     )\n\u001b[1;32m-> 1729\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1742\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1744\u001b[0m }\n\u001b[0;32m   1745\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2070\u001b[0m ):\n\u001b[0;32m   2071\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2072\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2074\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    931\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 634s 12s/step - loss: 2.1397 - accuracy: 0.3280 - val_loss: 3.9212 - val_accuracy: 0.3225\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 624s 12s/step - loss: 1.2078 - accuracy: 0.6530 - val_loss: 2.3165 - val_accuracy: 0.4000\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 624s 12s/step - loss: 0.7689 - accuracy: 0.7982 - val_loss: 1.7876 - val_accuracy: 0.4505\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 623s 12s/step - loss: 0.5303 - accuracy: 0.8702 - val_loss: 1.7462 - val_accuracy: 0.4865\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 622s 12s/step - loss: 0.3673 - accuracy: 0.9060 - val_loss: 1.6435 - val_accuracy: 0.4919\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 622s 12s/step - loss: 0.2807 - accuracy: 0.9286 - val_loss: 1.5580 - val_accuracy: 0.5225\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 623s 12s/step - loss: 0.2131 - accuracy: 0.9488 - val_loss: 1.7168 - val_accuracy: 0.5207\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 620s 12s/step - loss: 0.1680 - accuracy: 0.9571 - val_loss: 1.6727 - val_accuracy: 0.5081\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 624s 12s/step - loss: 0.1293 - accuracy: 0.9750 - val_loss: 1.9101 - val_accuracy: 0.4973\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 623s 12s/step - loss: 0.1122 - accuracy: 0.9732 - val_loss: 1.9704 - val_accuracy: 0.4865\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9643Restoring model weights from the end of the best epoch: 6.\n",
      "53/53 [==============================] - 621s 12s/step - loss: 0.1211 - accuracy: 0.9643 - val_loss: 1.8872 - val_accuracy: 0.4973\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d01923d0c0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 636s 12s/step - loss: 2.0370 - accuracy: 0.3589 - val_loss: 3.1515 - val_accuracy: 0.3063\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 625s 12s/step - loss: 1.2292 - accuracy: 0.6673 - val_loss: 2.2169 - val_accuracy: 0.3802\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 627s 12s/step - loss: 0.8834 - accuracy: 0.7738 - val_loss: 1.8460 - val_accuracy: 0.4613\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 628s 12s/step - loss: 0.6346 - accuracy: 0.8524 - val_loss: 1.7339 - val_accuracy: 0.4883\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 625s 12s/step - loss: 0.4394 - accuracy: 0.9125 - val_loss: 1.7410 - val_accuracy: 0.5225\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 627s 12s/step - loss: 0.3575 - accuracy: 0.9339 - val_loss: 1.7289 - val_accuracy: 0.5225\n",
      "Epoch 7/15\n",
      "26/53 [=============>................] - ETA: 4:07 - loss: 0.2796 - accuracy: 0.9495"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m validation_steps_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(validation_data_gen\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      4\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1573 images belonging to 13 classes.\n",
      "Found 662 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(zoom_range = 0.3, validation_split=0.3)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(244,244), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"khateeb_data\", target_size=(244,244), shuffle=True, class_mode=\"categorical\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50/50 [==============================] - 638s 13s/step - loss: 2.4459 - accuracy: 0.1964 - val_loss: 3.6285 - val_accuracy: 0.1541\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 631s 13s/step - loss: 2.0912 - accuracy: 0.3109 - val_loss: 2.2343 - val_accuracy: 0.2689\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 628s 13s/step - loss: 1.9095 - accuracy: 0.3566 - val_loss: 2.1856 - val_accuracy: 0.2946\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 627s 13s/step - loss: 1.8071 - accuracy: 0.4170 - val_loss: 2.0528 - val_accuracy: 0.3112\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 626s 13s/step - loss: 1.6951 - accuracy: 0.4495 - val_loss: 1.9446 - val_accuracy: 0.3429\n",
      "Epoch 6/15\n",
      "50/50 [==============================] - 626s 13s/step - loss: 1.5845 - accuracy: 0.4838 - val_loss: 1.9475 - val_accuracy: 0.3595\n",
      "Epoch 7/15\n",
      "50/50 [==============================] - 624s 13s/step - loss: 1.4589 - accuracy: 0.5283 - val_loss: 1.8889 - val_accuracy: 0.3505\n",
      "Epoch 8/15\n",
      "50/50 [==============================] - 624s 13s/step - loss: 1.3962 - accuracy: 0.5308 - val_loss: 1.8765 - val_accuracy: 0.3746\n",
      "Epoch 9/15\n",
      "50/50 [==============================] - 623s 12s/step - loss: 1.2912 - accuracy: 0.5779 - val_loss: 1.7829 - val_accuracy: 0.3792\n",
      "Epoch 10/15\n",
      "50/50 [==============================] - 623s 12s/step - loss: 1.2190 - accuracy: 0.5880 - val_loss: 1.8166 - val_accuracy: 0.4018\n",
      "Epoch 11/15\n",
      "50/50 [==============================] - 624s 12s/step - loss: 1.1661 - accuracy: 0.6186 - val_loss: 1.7695 - val_accuracy: 0.4215\n",
      "Epoch 12/15\n",
      "50/50 [==============================] - 624s 13s/step - loss: 1.0945 - accuracy: 0.6580 - val_loss: 1.6948 - val_accuracy: 0.4426\n",
      "Epoch 13/15\n",
      "50/50 [==============================] - 623s 12s/step - loss: 1.0579 - accuracy: 0.6510 - val_loss: 1.7393 - val_accuracy: 0.4698\n",
      "Epoch 14/15\n",
      "50/50 [==============================] - 623s 12s/step - loss: 0.9596 - accuracy: 0.6904 - val_loss: 1.7515 - val_accuracy: 0.4517\n",
      "Epoch 15/15\n",
      "50/50 [==============================] - 627s 13s/step - loss: 0.9296 - accuracy: 0.7025 - val_loss: 1.6839 - val_accuracy: 0.4698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cfeb5f5600>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50/50 [==============================] - 637s 13s/step - loss: 2.3900 - accuracy: 0.2219 - val_loss: 3.7924 - val_accuracy: 0.2508\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 625s 13s/step - loss: 1.8711 - accuracy: 0.4107 - val_loss: 2.0142 - val_accuracy: 0.3701\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 624s 13s/step - loss: 1.6161 - accuracy: 0.5175 - val_loss: 1.8161 - val_accuracy: 0.4305\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 627s 13s/step - loss: 1.4021 - accuracy: 0.6122 - val_loss: 1.6588 - val_accuracy: 0.4592\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 625s 13s/step - loss: 1.2538 - accuracy: 0.6561 - val_loss: 1.6112 - val_accuracy: 0.4773\n",
      "Epoch 6/15\n",
      "50/50 [==============================] - 622s 12s/step - loss: 1.0486 - accuracy: 0.7292 - val_loss: 1.5571 - val_accuracy: 0.4653\n",
      "Epoch 7/15\n",
      "50/50 [==============================] - 626s 13s/step - loss: 0.9176 - accuracy: 0.7641 - val_loss: 1.4832 - val_accuracy: 0.5030\n",
      "Epoch 8/15\n",
      "50/50 [==============================] - 626s 13s/step - loss: 0.8175 - accuracy: 0.7889 - val_loss: 1.5244 - val_accuracy: 0.4834\n",
      "Epoch 9/15\n",
      "50/50 [==============================] - 625s 13s/step - loss: 0.7498 - accuracy: 0.7997 - val_loss: 1.4682 - val_accuracy: 0.5181\n",
      "Epoch 10/15\n",
      "50/50 [==============================] - 625s 13s/step - loss: 0.6659 - accuracy: 0.8264 - val_loss: 1.4676 - val_accuracy: 0.5045\n",
      "Epoch 11/15\n",
      "50/50 [==============================] - 625s 13s/step - loss: 0.5982 - accuracy: 0.8442 - val_loss: 1.4257 - val_accuracy: 0.5106\n",
      "Epoch 12/15\n",
      "50/50 [==============================] - 625s 13s/step - loss: 0.5485 - accuracy: 0.8589 - val_loss: 1.3543 - val_accuracy: 0.5438\n",
      "Epoch 13/15\n",
      "50/50 [==============================] - 622s 12s/step - loss: 0.4909 - accuracy: 0.8735 - val_loss: 1.3657 - val_accuracy: 0.5438\n",
      "Epoch 14/15\n",
      "50/50 [==============================] - 625s 13s/step - loss: 0.4375 - accuracy: 0.8862 - val_loss: 1.4182 - val_accuracy: 0.5665\n",
      "Epoch 15/15\n",
      "50/50 [==============================] - 624s 13s/step - loss: 0.4276 - accuracy: 0.8849 - val_loss: 1.4254 - val_accuracy: 0.5438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d012f9d900>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50/50 [==============================] - 647s 13s/step - loss: 2.6834 - accuracy: 0.1608 - val_loss: 3.6446 - val_accuracy: 0.2039\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 634s 13s/step - loss: 2.1684 - accuracy: 0.2943 - val_loss: 2.2294 - val_accuracy: 0.2795\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 634s 13s/step - loss: 1.8226 - accuracy: 0.4069 - val_loss: 2.0906 - val_accuracy: 0.3082\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 637s 13s/step - loss: 1.6611 - accuracy: 0.4577 - val_loss: 2.0813 - val_accuracy: 0.3127\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 632s 13s/step - loss: 1.4080 - accuracy: 0.5493 - val_loss: 1.9909 - val_accuracy: 0.3550\n",
      "Epoch 6/15\n",
      "50/50 [==============================] - 634s 13s/step - loss: 1.2708 - accuracy: 0.6046 - val_loss: 1.9354 - val_accuracy: 0.3444\n",
      "Epoch 7/15\n",
      "50/50 [==============================] - 636s 13s/step - loss: 1.0926 - accuracy: 0.6529 - val_loss: 1.8030 - val_accuracy: 0.3973\n",
      "Epoch 8/15\n",
      "50/50 [==============================] - 637s 13s/step - loss: 0.9669 - accuracy: 0.7107 - val_loss: 1.7353 - val_accuracy: 0.4245\n",
      "Epoch 9/15\n",
      "50/50 [==============================] - 636s 13s/step - loss: 0.8888 - accuracy: 0.7247 - val_loss: 1.6397 - val_accuracy: 0.4728\n",
      "Epoch 10/15\n",
      "50/50 [==============================] - 638s 13s/step - loss: 0.7988 - accuracy: 0.7546 - val_loss: 1.5622 - val_accuracy: 0.4879\n",
      "Epoch 11/15\n",
      "50/50 [==============================] - 634s 13s/step - loss: 0.7520 - accuracy: 0.7552 - val_loss: 1.5262 - val_accuracy: 0.5196\n",
      "Epoch 12/15\n",
      "50/50 [==============================] - 636s 13s/step - loss: 0.6427 - accuracy: 0.8029 - val_loss: 1.6157 - val_accuracy: 0.5483\n",
      "Epoch 13/15\n",
      "50/50 [==============================] - 633s 13s/step - loss: 0.6311 - accuracy: 0.8023 - val_loss: 1.5881 - val_accuracy: 0.5347\n",
      "Epoch 14/15\n",
      "50/50 [==============================] - 639s 13s/step - loss: 0.5864 - accuracy: 0.8239 - val_loss: 1.6186 - val_accuracy: 0.5151\n",
      "Epoch 15/15\n",
      "50/50 [==============================] - 636s 13s/step - loss: 0.4934 - accuracy: 0.8442 - val_loss: 1.6419 - val_accuracy: 0.5151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d012f9dc30>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moath\\Downloads\\data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.join(current_directory, \"data\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_bishop\n",
      "black_king\n",
      "black_knight\n",
      "Image not in ext list C:\\Users\\Moath\\Downloads\\data\\black_knight\\.DS_Store\n",
      "black_pawn\n",
      "black_queen\n",
      "black_rook\n",
      "empty\n",
      "white_bishop\n",
      "white_king\n",
      "white_knight\n",
      "white_pawn\n",
      "white_queen\n",
      "white_rook\n"
     ]
    }
   ],
   "source": [
    "folders = ['train', 'test']\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n",
    "for image_class in os.listdir(path): \n",
    "  print(image_class)\n",
    "  for image in os.listdir(os.path.join(path, image_class)):\n",
    "      image_path = os.path.join(path, image_class, image)\n",
    "      try: \n",
    "          img = cv2.imread(image_path)\n",
    "          tip = imghdr.what(image_path)\n",
    "          if tip not in image_exts: \n",
    "              print('Image not in ext list {}'.format(image_path))\n",
    "              os.remove(image_path)\n",
    "      except Exception as e: \n",
    "          print('Issue with image {}'.format(image_path))\n",
    "          # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2227 images belonging to 13 classes.\n",
      "Found 940 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator(zoom_range = 0.3, validation_split=0.3)\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"data\", target_size=(244,244), shuffle=True, class_mode=\"categorical\", subset=\"training\")\n",
    "validation_data_gen = trdata.flow_from_directory(directory=\"data\", target_size=(244,244), shuffle=True, class_mode=\"categorical\", subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 [==============================] - 654s 9s/step - loss: 2.7477 - accuracy: 0.1320 - val_loss: 2.8544 - val_accuracy: 0.1777\n",
      "Epoch 2/15\n",
      "70/70 [==============================] - 612s 9s/step - loss: 2.2414 - accuracy: 0.2434 - val_loss: 1.9667 - val_accuracy: 0.3489\n",
      "Epoch 3/15\n",
      "70/70 [==============================] - 609s 9s/step - loss: 1.9318 - accuracy: 0.3278 - val_loss: 1.6875 - val_accuracy: 0.4468\n",
      "Epoch 4/15\n",
      "70/70 [==============================] - 612s 9s/step - loss: 1.6723 - accuracy: 0.4185 - val_loss: 1.5065 - val_accuracy: 0.5032\n",
      "Epoch 5/15\n",
      "70/70 [==============================] - 611s 9s/step - loss: 1.4946 - accuracy: 0.4859 - val_loss: 1.3235 - val_accuracy: 0.5606\n",
      "Epoch 6/15\n",
      "70/70 [==============================] - 615s 9s/step - loss: 1.2946 - accuracy: 0.5424 - val_loss: 1.2437 - val_accuracy: 0.5596\n",
      "Epoch 7/15\n",
      "70/70 [==============================] - 619s 9s/step - loss: 1.1378 - accuracy: 0.6075 - val_loss: 1.1647 - val_accuracy: 0.5872\n",
      "Epoch 8/15\n",
      "70/70 [==============================] - 610s 9s/step - loss: 1.0521 - accuracy: 0.6264 - val_loss: 1.0015 - val_accuracy: 0.6298\n",
      "Epoch 9/15\n",
      "70/70 [==============================] - 613s 9s/step - loss: 0.9519 - accuracy: 0.6731 - val_loss: 0.9683 - val_accuracy: 0.6691\n",
      "Epoch 10/15\n",
      "70/70 [==============================] - 612s 9s/step - loss: 0.8275 - accuracy: 0.7176 - val_loss: 0.9217 - val_accuracy: 0.6830\n",
      "Epoch 11/15\n",
      "70/70 [==============================] - 615s 9s/step - loss: 0.7627 - accuracy: 0.7328 - val_loss: 0.8540 - val_accuracy: 0.6840\n",
      "Epoch 12/15\n",
      "70/70 [==============================] - 612s 9s/step - loss: 0.7236 - accuracy: 0.7454 - val_loss: 0.7876 - val_accuracy: 0.7255\n",
      "Epoch 13/15\n",
      "70/70 [==============================] - 613s 9s/step - loss: 0.6567 - accuracy: 0.7759 - val_loss: 0.8419 - val_accuracy: 0.6957\n",
      "Epoch 14/15\n",
      "70/70 [==============================] - 622s 9s/step - loss: 0.6273 - accuracy: 0.7881 - val_loss: 0.8205 - val_accuracy: 0.7000\n",
      "Epoch 15/15\n",
      "70/70 [==============================] - 616s 9s/step - loss: 0.5777 - accuracy: 0.8087 - val_loss: 0.7562 - val_accuracy: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d00b5b7a60>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = \"imagenet\", include_top = False)\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(vgg.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(13, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.90, nesterov=True)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 [==============================] - 607s 9s/step - loss: 2.7291 - accuracy: 0.1132 - val_loss: 2.5023 - val_accuracy: 0.1723\n",
      "Epoch 2/15\n",
      "70/70 [==============================] - 605s 9s/step - loss: 2.4086 - accuracy: 0.1608 - val_loss: 2.1897 - val_accuracy: 0.2702\n",
      "Epoch 3/15\n",
      "70/70 [==============================] - 601s 9s/step - loss: 2.2193 - accuracy: 0.2380 - val_loss: 1.9891 - val_accuracy: 0.3606\n",
      "Epoch 4/15\n",
      "70/70 [==============================] - 605s 9s/step - loss: 2.0259 - accuracy: 0.2955 - val_loss: 1.8615 - val_accuracy: 0.3851\n",
      "Epoch 5/15\n",
      "31/70 [============>.................] - ETA: 3:57 - loss: 1.9495 - accuracy: 0.3136"
     ]
    }
   ],
   "source": [
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / 32)\n",
    "validation_steps_per_epoch = np.ceil(validation_data_gen.samples / 32)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True,verbose=1)\n",
    "\n",
    "model.fit(train_data_gen, steps_per_epoch = training_steps_per_epoch, validation_data=validation_data_gen, validation_steps=validation_steps_per_epoch, epochs=15, verbose=1, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
